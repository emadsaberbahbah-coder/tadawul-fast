#!/usr/bin/env python3
"""
Tadawul Fast Bridge - Legacy Stock Microservice
Version: 4.1.0

Description:
  Lightweight stock market data bridge with FastAPI

Key Features:
- Simple Argaam/Tadawul integration (with mock fallback)
- CSV export
- Optional Google Sheets export (service account)
- Basic in-memory TTL cache with hit/miss stats
- Health & Stats endpoints aligned with v4 dashboard:
    - /health              → simple health (for Render)
    - /api/v1/health       → detailed status (used by index.html dashboard)
    - /api/v1/stats        → performance & cache metrics

Notes:
- This is a self-contained legacy microservice, separate from your main
  tadawul-fast bridge. It is safe to run alone on Render or locally.
"""

from __future__ import annotations

import asyncio
import csv
import io
import json
import logging
import os
import random
import time
from contextlib import asynccontextmanager
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple

import aiohttp
import gspread
from fastapi import FastAPI, HTTPException, Query, Request, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from google.oauth2.service_account import Credentials
from pydantic import BaseModel, Field
from slowapi import Limiter
from slowapi.util import get_remote_address

# =============================================================================
# Settings / Configuration
# =============================================================================


class Settings:
    """Application settings loaded from environment with sane defaults."""

    def __init__(self) -> None:
        # Prefer SERVICE_NAME / SERVICE_VERSION (aligned with render.yaml)
        self.APP_NAME: str = (
            os.getenv("SERVICE_NAME")
            or os.getenv("APP_NAME")
            or "Tadawul Fast Bridge - Legacy"
        )
        self.VERSION: str = (
            os.getenv("SERVICE_VERSION")
            or os.getenv("APP_VERSION")
            or "4.1.0"
        )

        # External APIs
        self.ARGAAM_API_KEY: str = os.getenv("ARGAAM_API_KEY", "")
        self.ARGAAM_BASE_URL: str = os.getenv(
            "ARGAAM_BASE_URL", "https://api.argaam.com"
        )
        self.TADAWUL_BASE_URL: str = os.getenv(
            "TADAWUL_BASE_URL", "https://www.tadawul.com.sa"
        )

        # Optional security token (aligned with main service APP_TOKEN usage)
        self.APP_TOKEN: str = os.getenv("APP_TOKEN", "")

        # Google Sheets credentials (JSON string)
        # Support multiple env names for compatibility
        self.GOOGLE_CREDENTIALS_JSON: str = (
            os.getenv("GOOGLE_SHEETS_CREDENTIALS")
            or os.getenv("GOOGLE_SHEETS_CREDENTIALS_JSON")
            or os.getenv("GOOGLE_CREDENTIALS", "")
        )

        # Cache
        self.CACHE_TTL: int = int(os.getenv("CACHE_TTL", "300"))
        self.CACHE_MAXSIZE: int = int(os.getenv("CACHE_MAXSIZE", "1000"))

        # Rate Limiting (placeholder)
        self.RATE_LIMIT_PER_MINUTE: int = int(
            os.getenv("RATE_LIMIT_PER_MINUTE", "60")
        )

        # Environment / misc
        self.ENVIRONMENT: str = os.getenv("ENVIRONMENT", "production")

        # Logging
        self.LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO").upper()


settings = Settings()

# =============================================================================
# Logging Setup
# =============================================================================

logging.basicConfig(
    level=getattr(logging, settings.LOG_LEVEL, logging.INFO),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger("tadawul-legacy")

# =============================================================================
# Models
# =============================================================================


class StockSymbol(BaseModel):
    """Unified stock symbol snapshot."""

    symbol: str
    name_ar: Optional[str] = None
    name_en: Optional[str] = None
    sector: Optional[str] = None
    market_cap: Optional[float] = None
    last_price: Optional[float] = None
    change: Optional[float] = None
    change_percent: Optional[float] = None
    volume: Optional[int] = None
    timestamp: Optional[str] = None

    class Config:
        json_encoders = {datetime: lambda v: v.isoformat()}


class MarketData(BaseModel):
    """Simple market summary model."""

    timestamp: str
    market_index: Optional[float] = None
    market_change: Optional[float] = None
    market_change_percent: Optional[float] = None
    turnover: Optional[float] = None
    volume: Optional[int] = None
    advancers: Optional[int] = None
    decliners: Optional[int] = None
    unchanged: Optional[int] = None


class TokenData(BaseModel):
    """Placeholder JWT token data (not used in endpoints, kept for future)."""

    username: Optional[str] = None
    scopes: List[str] = Field(default_factory=list)


# =============================================================================
# Rate Limiting (placeholder, not applied per-route yet)
# =============================================================================

limiter = Limiter(key_func=get_remote_address)

# =============================================================================
# In-memory TTL Cache with hit/miss stats
# =============================================================================


class DataCache:
    """Simple in-memory TTL cache with basic stats."""

    def __init__(self, maxsize: int = 1000, ttl: int = 300) -> None:
        self._store: Dict[str, Tuple[float, Any]] = {}
        self.maxsize = maxsize
        self.ttl = ttl
        self.hits = 0
        self.misses = 0

    def get(self, key: str) -> Optional[Any]:
        now = time.time()
        item = self._store.get(key)
        if not item:
            self.misses += 1
            return None

        expires_at, value = item
        if expires_at < now:
            # expired
            self.misses += 1
            self._store.pop(key, None)
            return None

        self.hits += 1
        return value

    def set(self, key: str, value: Any) -> None:
        if len(self._store) >= self.maxsize:
            # Simple eviction: remove the first key
            try:
                first_key = next(iter(self._store.keys()))
                self._store.pop(first_key, None)
            except StopIteration:
                pass
        self._store[key] = (time.time() + self.ttl, value)

    def clear(self) -> None:
        self._store.clear()
        self.hits = 0
        self.misses = 0

    def stats(self) -> Dict[str, Any]:
        total = self.hits + self.misses
        hit_rate = (self.hits * 100.0 / total) if total > 0 else 0.0
        return {
            "size": len(self._store),
            "ttl": self.ttl,
            "maxsize": self.maxsize,
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": round(hit_rate, 1),
        }


cache = DataCache(maxsize=settings.CACHE_MAXSIZE, ttl=settings.CACHE_TTL)

# =============================================================================
# Google Sheets Service
# =============================================================================


class GoogleSheetsService:
    """Google Sheets integration using gspread (sync, wrapped in executor for async)."""

    def __init__(self, credentials_json: Optional[str] = None):
        self.credentials_json = credentials_json or settings.GOOGLE_CREDENTIALS_JSON
        self.client: Optional[gspread.Client] = None

        if self.credentials_json:
            self._init_client()
        else:
            logger.warning(
                "Google Sheets credentials not configured; export to Sheets will be disabled."
            )

    def _init_client(self) -> None:
        """Initialize Google Sheets client."""
        try:
            creds_dict = json.loads(self.credentials_json)
            creds = Credentials.from_service_account_info(creds_dict)
            self.client = gspread.authorize(creds)
            logger.info("Google Sheets client initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Google Sheets client: {e}")
            self.client = None

    def _update_sheet_sync(
        self,
        spreadsheet_id: str,
        sheet_name: str,
        data: List[List[Any]],
    ) -> Dict[str, Any]:
        """Synchronous part of sheet update (runs in executor)."""
        if not self.client:
            raise RuntimeError("Google Sheets client is not initialized")

        spreadsheet = self.client.open_by_key(spreadsheet_id)
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
        except gspread.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(
                title=sheet_name,
                rows=len(data) + 10,
                cols=len(data[0]) + 5,
            )

        worksheet.clear()
        worksheet.update(data, value_input_option="USER_ENTERED")
        return {"status": "success", "rows_updated": len(data)}

    async def update_sheet(
        self,
        spreadsheet_id: str,
        sheet_name: str,
        data: List[List[Any]],
    ) -> Dict[str, Any]:
        """Async wrapper to update Google Sheet without blocking event loop."""
        if not self.client:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Google Sheets not configured",
            )

        try:
            loop = asyncio.get_running_loop()
            result = await loop.run_in_executor(
                None,
                self._update_sheet_sync,
                spreadsheet_id,
                sheet_name,
                data,
            )
            return result
        except Exception as e:
            logger.error(f"Google Sheets error: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Google Sheets error: {str(e)}",
            )


# =============================================================================
# HTTP Client
# =============================================================================


class HTTPClient:
    """HTTP client with simple retry logic using aiohttp."""

    def __init__(self) -> None:
        self.session: Optional[aiohttp.ClientSession] = None

    async def __aenter__(self) -> "HTTPClient":
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        if self.session:
            await self.session.close()

    async def fetch_json(
        self, url: str, params: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Fetch JSON data from the given URL."""
        if self.session is None:
            raise RuntimeError("HTTPClient session is not initialized")

        try:
            async with self.session.get(url, params=params) as response:
                if response.status == 200:
                    return await response.json()
                raise HTTPException(
                    status_code=response.status,
                    detail=f"HTTP error {response.status}",
                )
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"HTTP request failed: {e}")
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail=f"Request failed: {str(e)}",
            )


# =============================================================================
# Stock Data Service
# =============================================================================


class StockDataService:
    """Stock data service: Argaam + mock + basic Tadawul HTML summary."""

    def __init__(self) -> None:
        self.http_client = HTTPClient()
        self.sheets_service = GoogleSheetsService()

    async def get_symbol_data(
        self, symbol: str, use_cache: bool = True
    ) -> Dict[str, Any]:
        """Get symbol data from Argaam or mock fallback."""
        cache_key = f"symbol:{symbol}"

        if use_cache:
            cached = cache.get(cache_key)
            if cached is not None:
                logger.debug(f"Cache hit for {symbol}")
                return cached

        try:
            if settings.ARGAAM_API_KEY:
                async with self.http_client as client:
                    data = await client.fetch_json(
                        f"{settings.ARGAAM_BASE_URL}/v1.0/symbols/{symbol}",
                        params={"apikey": settings.ARGAAM_API_KEY},
                    )
            else:
                data = self._generate_mock_data(symbol)

            processed_data = self._process_data(data, symbol)
            cache.set(cache_key, processed_data)
            return processed_data

        except Exception as e:
            logger.error(f"Failed to fetch {symbol}, using mock data: {e}")
            return self._process_data(self._generate_mock_data(symbol), symbol)

    def _process_data(self, raw_data: Dict[str, Any], symbol: str) -> Dict[str, Any]:
        """Normalize raw data into a unified structure."""
        return {
            "symbol": symbol,
            "name_ar": raw_data.get("arabicName", f"شركة {symbol}"),
            "name_en": raw_data.get("englishName", f"Company {symbol}"),
            "sector": raw_data.get("sector", "Unknown"),
            "market_cap": raw_data.get("marketCap"),
            "last_price": raw_data.get("lastPrice", raw_data.get("price")),
            "change": raw_data.get("change"),
            "change_percent": raw_data.get("changePercent"),
            "volume": raw_data.get("volume"),
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

    def _generate_mock_data(self, symbol: str) -> Dict[str, Any]:
        """Generate mock data for testing / fallback."""
        return {
            "arabicName": f"شركة {symbol}",
            "englishName": f"Company {symbol}",
            "sector": random.choice(["البنوك", "البتروكيماويات", "الاتصالات"]),
            "marketCap": random.uniform(10_000_000, 1_000_000_000),
            "lastPrice": random.uniform(10, 500),
            "change": random.uniform(-10, 10),
            "changePercent": random.uniform(-5, 5),
            "volume": random.randint(100_000, 10_000_000),
        }

    async def get_market_summary(self) -> MarketData:
        """Get market summary from Tadawul or fallback dummy data."""
        cache_key = "market_summary"
        cached = cache.get(cache_key)
        if cached:
            return MarketData(**cached)

        try:
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=10)
            ) as session:
                async with session.get(
                    f"{settings.TADAWUL_BASE_URL}/market-summary"
                ) as response:
                    if response.status == 200:
                        html = await response.text()
                        data = self._parse_market_summary(html)
                        cache.set(cache_key, data)
                        return MarketData(**data)
                    logger.warning(
                        f"Tadawul summary HTTP {response.status}, using fallback"
                    )
        except Exception as e:
            logger.warning(
                f"Failed to fetch Tadawul market summary, using fallback: {e}"
            )

        # Fallback default data
        data = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "market_index": 11234.56,
            "market_change": 45.67,
            "market_change_percent": 0.41,
            "turnover": 3_456_789_012.34,
            "volume": 123_456_789,
            "advancers": 145,
            "decliners": 67,
            "unchanged": 23,
        }
        cache.set(cache_key, data)
        return MarketData(**data)

    def _parse_market_summary(self, html: str) -> Dict[str, Any]:
        """
        Parse market summary from Tadawul HTML.

        NOTE: Currently returns dummy values. You can implement real parsing
        with BeautifulSoup here if you want live HTML scraping.
        """
        # from bs4 import BeautifulSoup
        # soup = BeautifulSoup(html, "html.parser")
        # TODO: extract real values from soup
        return {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "market_index": 11234.56,
            "market_change": 45.67,
            "market_change_percent": 0.41,
            "turnover": 3_456_789_012.34,
            "volume": 123_456_789,
            "advancers": 145,
            "decliners": 67,
            "unchanged": 23,
        }


# =============================================================================
# Application Setup (lifespan)
# =============================================================================


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager (startup/shutdown)."""
    logger.info(f"Starting {settings.APP_NAME} v{settings.VERSION}")

    # Initialize services
    app.state.stock_service = StockDataService()

    # Metrics for /api/v1/health and /api/v1/stats
    app.state.start_time = time.time()
    app.state.request_count = 0
    app.state.total_response_time = 0.0

    # Pre-cache market summary (non-blocking if it fails)
    try:
        await app.state.stock_service.get_market_summary()
        logger.info("Initial market summary pre-loaded")
    except Exception as e:
        logger.warning(f"Failed to pre-load initial data: {e}")

    yield

    # Shutdown
    logger.info("Shutting down legacy microservice")
    cache.clear()


app = FastAPI(
    title=settings.APP_NAME,
    version=settings.VERSION,
    description=(
        "Legacy Tadawul stock data bridge "
        "(simple Argaam/Tadawul service with CSV & Google Sheets export)"
    ),
    lifespan=lifespan,
)

# Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # For legacy microservice; tighten if needed
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.add_middleware(GZipMiddleware, minimum_size=1_000)

# Store limiter for potential future use
app.state.limiter = limiter

# =============================================================================
# HTTP Middleware (performance metrics)
# =============================================================================


@app.middleware("http")
async def add_process_time_header(request: Request, call_next):
    """Add process time header and update basic performance stats."""
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    response.headers["X-Process-Time"] = f"{process_time:.6f}"

    # Update app metrics
    try:
        request.app.state.request_count += 1
        request.app.state.total_response_time += process_time
    except Exception:
        # If state not yet initialized, ignore
        pass

    return response


# =============================================================================
# Endpoints
# =============================================================================


@app.get("/")
async def root():
    """Root endpoint."""
    return {
        "service": settings.APP_NAME,
        "version": settings.VERSION,
        "status": "running",
        "environment": settings.ENVIRONMENT,
        "timestamp": datetime.now(timezone.utc).isoformat(),
    }


@app.get("/health")
async def health():
    """
    Simple health check endpoint.

    Used by Render native healthCheck (render.yaml -> path: /health)
    """
    return {
        "status": "healthy",
        "timestamp": datetime.now(timezone.utc).isoformat(),
    }


@app.get("/api/v1/health")
async def detailed_health(request: Request):
    """
    Detailed health endpoint.

    Dashboard expects:
      - status
      - uptime_seconds
      - environment
      - cache_status
      - performance
      - services / google_sheets_status
    """
    now = time.time()
    start_time = getattr(request.app.state, "start_time", now)
    uptime_seconds = int(now - start_time)

    service: StockDataService = request.app.state.stock_service
    sheets_status = (
        "connected" if service.sheets_service.client is not None else "disabled"
    )

    cache_stats = cache.stats()

    total_requests = getattr(request.app.state, "request_count", 0)
    total_resp_time = getattr(request.app.state, "total_response_time", 0.0)
    avg_response_ms = (
        (total_resp_time / total_requests) * 1000.0
        if total_requests > 0
        else 0.0
    )

    return {
        "status": "healthy",
        "environment": settings.ENVIRONMENT,
        "version": settings.VERSION,
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "uptime_seconds": uptime_seconds,
        "api_status": "healthy",
        "google_sheets_status": sheets_status,
        "services": {
            "google_sheets": sheets_status,
            "cache": "enabled",
        },
        "cache_status": {
            "status": "enabled",
            **cache_stats,
        },
        "performance": {
            "total_requests": total_requests,
            "avg_response_time_ms": round(avg_response_ms, 2),
        },
    }


@app.get("/api/v1/stats")
async def stats(request: Request):
    """
    Stats endpoint used by dashboard for metrics.

    Returns:
      {
        "performance": { "total_requests": ..., "avg_response_time_ms": ... },
        "cache": { "hits": ..., "misses": ..., "hit_rate": ..., "size": ... }
      }
    """
    total_requests = getattr(request.app.state, "request_count", 0)
    total_resp_time = getattr(request.app.state, "total_response_time", 0.0)
    avg_response_ms = (
        (total_resp_time / total_requests) * 1000.0
        if total_requests > 0
        else 0.0
    )

    return {
        "performance": {
            "total_requests": total_requests,
            "avg_response_time_ms": round(avg_response_ms, 2),
        },
        "cache": cache.stats(),
        "timestamp": datetime.now(timezone.utc).isoformat(),
    }


@app.get("/api/v1/symbols/{symbol}", response_model=StockSymbol)
async def get_symbol(
    request: Request,
    symbol: str,
    use_cache: bool = Query(True, description="Use cached data"),
):
    """Get single symbol data."""
    service: StockDataService = request.app.state.stock_service
    data = await service.get_symbol_data(symbol, use_cache)
    return StockSymbol(**data)


@app.get("/api/v1/market/summary", response_model=MarketData)
async def get_market_summary(request: Request):
    """Get market summary."""
    service: StockDataService = request.app.state.stock_service
    data = await service.get_market_summary()
    return data


@app.get("/api/v1/symbols", response_model=List[StockSymbol])
async def get_multiple_symbols(
    request: Request,
    symbols: str = Query(..., description="Comma-separated symbols (max 10)"),
    use_cache: bool = Query(True, description="Use cached data"),
):
    """Get multiple symbols (simple batch endpoint)."""
    symbol_list = [s.strip() for s in symbols.split(",") if s.strip()]
    symbol_list = symbol_list[:10]  # Safety cap

    service: StockDataService = request.app.state.stock_service

    results: List[StockSymbol] = []
    for symbol in symbol_list:
        try:
            data = await service.get_symbol_data(symbol, use_cache)
            results.append(StockSymbol(**data))
        except Exception as e:
            logger.warning(f"Failed to fetch {symbol}: {e}")

    return results


@app.post("/api/v1/export/to-sheets")
async def export_to_sheets(
    request: Request,
    spreadsheet_id: str,
    sheet_name: str = "StockData",
    symbols: Optional[str] = None,
):
    """Export simple symbol snapshot to Google Sheets."""
    service: StockDataService = request.app.state.stock_service

    # Determine symbols
    if symbols:
        symbol_list = [s.strip() for s in symbols.split(",") if s.strip()]
    else:
        # Default sample symbols (can be changed)
        symbol_list = ["1211", "2222", "1180"]

    all_data: List[List[Any]] = []
    for symbol in symbol_list:
        try:
            data = await service.get_symbol_data(symbol, use_cache=True)
            row = [
                data.get("symbol", ""),
                data.get("name_en", ""),
                data.get("last_price", 0),
                data.get("change", 0),
                data.get("change_percent", 0),
                data.get("volume", 0),
                data.get("timestamp", datetime.now(timezone.utc).isoformat()),
            ]
            all_data.append(row)
        except Exception as e:
            logger.error(f"Failed to fetch {symbol} during export: {e}")

    if not all_data:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="No data to export",
        )

    # Headers
    headers = [
        ["Symbol", "Name", "Price", "Change", "Change%", "Volume", "Timestamp"]
    ]
    data_to_export = headers + all_data

    result = await service.sheets_service.update_sheet(
        spreadsheet_id, sheet_name, data_to_export
    )

    return {"status": "success", "exported": len(all_data), "details": result}


@app.get("/api/v1/export/csv/{symbol}")
async def export_csv(symbol: str):
    """Export a single symbol snapshot as CSV (no pandas dependency)."""
    service: StockDataService = app.state.stock_service
    data = await service.get_symbol_data(symbol, use_cache=True)

    # Order of columns
    columns = [
        "symbol",
        "name_en",
        "last_price",
        "change",
        "change_percent",
        "volume",
        "timestamp",
    ]

    # Build CSV via standard library
    buffer = io.StringIO()
    writer = csv.writer(buffer)

    # Header
    writer.writerow(columns)
    # Row
    writer.writerow([data.get(col, "") for col in columns])

    csv_data = buffer.getvalue()
    buffer.close()

    return StreamingResponse(
        iter([csv_data]),
        media_type="text/csv",
        headers={"Content-Disposition": f"attachment; filename={symbol}_data.csv"},
    )


# =============================================================================
# Error Handlers
# =============================================================================


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """HTTP exception handler."""
    logger.error(f"HTTP error: {exc.status_code} - {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": True,
            "code": exc.status_code,
            "message": exc.detail,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        },
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """General exception handler."""
    logger.error(f"Unexpected error: {exc}")
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "error": True,
            "code": 500,
            "message": "Internal server error",
            "timestamp": datetime.now(timezone.utc).isoformat(),
        },
    )


# =============================================================================
# Run Application (local dev only)
# =============================================================================

if __name__ == "__main__":
    import uvicorn

    logger.info("Starting legacy server on 0.0.0.0:8000 (dev mode)")
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level=settings.LOG_LEVEL.lower(),
    )
