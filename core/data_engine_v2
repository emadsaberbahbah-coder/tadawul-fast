"""
core/data_engine_v2.py
===============================================
Core Data & Analysis Engine - v2.0

Author: Emad Bahbah (with GPT-5.1 Thinking)

Key features
------------
- Async, multi-provider quote engine (FMP + optional EODHD + optional Finnhub).
- KSA (.SR) tickers are KSA-safe:
    • Never call EODHD directly for .SR symbols.
    • If the legacy core.data_engine is available, it is used as the
      primary KSA delegate (Tadawul / Argaam routing).
- Simple in-memory caching with TTL to reduce API calls.
- UnifiedQuote Pydantic model aligned with:
    • routes/enriched_quote.EnrichedQuoteResponse
    • legacy_service (v1/quote + v1/legacy/sheet-rows)
    • 9-page Google Sheets dashboard philosophy
- Basic AI-style scoring:
    • Value / Quality / Momentum / Opportunity + Recommendation
- Extremely defensive:
    • Never raises on normal usage (returns MISSING with error instead).

Environment variables
---------------------
ENABLED_PROVIDERS       # e.g. "fmp,eodhd,finnhub" (case-insensitive). Default: "fmp"
PRIMARY_PROVIDER        # (not enforced here – order of ENABLED_PROVIDERS is used)
FMP_API_KEY             # required for FMP provider
EODHD_BASE_URL          # optional; default "https://eodhd.com/api"
EODHD_API_KEY           # optional
FINNHUB_API_KEY         # optional
DATAENGINE_CACHE_TTL    # optional; seconds, default 120
DATAENGINE_TIMEOUT      # optional; per-provider timeout in seconds, default 10
LOCAL_TIMEZONE          # optional; default "Asia/Riyadh"
"""

from __future__ import annotations

import asyncio
import logging
import os
import time
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple

import httpx
from pydantic import BaseModel, Field

try:
    # Python 3.11+
    from zoneinfo import ZoneInfo
except Exception:  # pragma: no cover
    ZoneInfo = None  # type: ignore

logger = logging.getLogger(__name__)

# Optional import of v1 engine for KSA delegation
try:  # pragma: no cover - best-effort
    from core import data_engine as _v1_engine  # type: ignore

    _HAS_V1_ENGINE = True
except Exception:  # pragma: no cover - if core.data_engine is missing
    _v1_engine = None  # type: ignore
    _HAS_V1_ENGINE = False


# ============================================================================
# ProviderSource & UnifiedQuote models
# ============================================================================


class ProviderSource(BaseModel):
    provider: str
    weight: Optional[float] = None
    quality: Optional[float] = None
    note: Optional[str] = None


class UnifiedQuote(BaseModel):
    # Identity
    symbol: str = Field(..., description="Canonical symbol, e.g. 1120.SR, AAPL")
    name: Optional[str] = None
    company_name: Optional[str] = None
    sector: Optional[str] = None
    sub_sector: Optional[str] = None
    industry: Optional[str] = None
    market: Optional[str] = None          # e.g. "US", "KSA"
    market_region: Optional[str] = None   # alias for legacy engine / sheets
    exchange: Optional[str] = None
    currency: Optional[str] = None
    listing_date: Optional[str] = None  # YYYY-MM-DD if available

    # Capital structure
    shares_outstanding: Optional[float] = None
    free_float: Optional[float] = None

    # Price / liquidity
    last_price: Optional[float] = None
    price: Optional[float] = None
    previous_close: Optional[float] = None
    prev_close: Optional[float] = None  # alias for legacy_service
    open: Optional[float] = None
    high: Optional[float] = None
    low: Optional[float] = None
    change: Optional[float] = None
    change_percent: Optional[float] = None
    change_pct: Optional[float] = None

    high_52w: Optional[float] = None
    low_52w: Optional[float] = None
    fifty_two_week_high: Optional[float] = None
    fifty_two_week_low: Optional[float] = None
    position_52w_percent: Optional[float] = None
    fifty_two_week_position: Optional[float] = None

    volume: Optional[float] = None
    avg_volume_30d: Optional[float] = None
    average_volume_30d: Optional[float] = None
    avg_volume: Optional[float] = None
    value_traded: Optional[float] = None
    turnover_rate: Optional[float] = None
    bid_price: Optional[float] = None
    ask_price: Optional[float] = None
    bid_size: Optional[float] = None
    ask_size: Optional[float] = None
    spread_percent: Optional[float] = None
    liquidity_score: Optional[float] = None

    # Fundamentals
    eps_ttm: Optional[float] = None
    eps: Optional[float] = None
    pe_ratio: Optional[float] = None
    pe: Optional[float] = None
    pe_ttm: Optional[float] = None
    pb_ratio: Optional[float] = None
    pb: Optional[float] = None
    dividend_yield_percent: Optional[float] = None
    dividend_yield: Optional[float] = None
    dividend_payout_ratio: Optional[float] = None
    roe_percent: Optional[float] = None
    roe: Optional[float] = None
    roa_percent: Optional[float] = None
    roa: Optional[float] = None
    debt_to_equity: Optional[float] = None
    current_ratio: Optional[float] = None
    quick_ratio: Optional[float] = None
    market_cap: Optional[float] = None

    # Growth / profitability
    revenue_growth_percent: Optional[float] = None
    net_income_growth_percent: Optional[float] = None
    ebitda_margin_percent: Optional[float] = None
    operating_margin_percent: Optional[float] = None
    net_margin_percent: Optional[float] = None
    profit_margin: Optional[float] = None  # alias used in legacy_service

    # Valuation / risk
    ev_to_ebitda: Optional[float] = None
    price_to_sales: Optional[float] = None
    price_to_cash_flow: Optional[float] = None
    peg_ratio: Optional[float] = None
    beta: Optional[float] = None
    volatility_30d_percent: Optional[float] = None
    volatility_30d: Optional[float] = None

    # AI valuation & scores
    fair_value: Optional[float] = None
    upside_percent: Optional[float] = None
    valuation_label: Optional[str] = None
    value_score: Optional[float] = None
    quality_score: Optional[float] = None
    momentum_score: Optional[float] = None
    opportunity_score: Optional[float] = None
    recommendation: Optional[str] = None

    # Technicals
    rsi_14: Optional[float] = None
    macd: Optional[float] = None
    ma_20d: Optional[float] = None
    ma_50d: Optional[float] = None

    # Meta & providers
    data_quality: str = Field(
        "UNKNOWN", description="OK / PARTIAL / MISSING / STALE / UNKNOWN"
    )
    primary_provider: Optional[str] = None
    provider: Optional[str] = None
    data_source: Optional[str] = None  # alias for "Data Source" column on Sheets
    sources: Optional[List[ProviderSource]] = None

    # Timestamps
    last_updated_utc: Optional[datetime] = None
    last_updated_riyadh: Optional[datetime] = None
    as_of_utc: Optional[datetime] = None
    as_of_local: Optional[datetime] = None
    timezone: Optional[str] = None

    # Raw / errors
    error: Optional[str] = None
    raw: Optional[Dict[str, Any]] = None


@dataclass
class _CacheEntry:
    expires_at: float
    quote: UnifiedQuote


# ============================================================================
# DataEngine
# ============================================================================


class DataEngine:
    """
    Core async engine used by routes.enriched_quote and any AI analysis routes.

    Public async methods:
        - get_enriched_quote(symbol: str) -> UnifiedQuote
        - get_enriched_quotes(symbols: List[str]) -> List[UnifiedQuote]
    """

    def __init__(
        self,
        cache_ttl: Optional[int] = None,
        provider_timeout: Optional[int] = None,
        enabled_providers: Optional[List[str]] = None,
        enable_advanced_analysis: bool = True,
    ) -> None:
        # Config from env with sensible defaults
        self.cache_ttl: int = (
            cache_ttl
            if cache_ttl is not None
            else int(os.getenv("DATAENGINE_CACHE_TTL", "120") or "120")
        )
        self.provider_timeout: int = (
            provider_timeout
            if provider_timeout is not None
            else int(os.getenv("DATAENGINE_TIMEOUT", "10") or "10")
        )
        self.enable_advanced_analysis: bool = enable_advanced_analysis
        self.local_tz_name: str = os.getenv("LOCAL_TIMEZONE", "Asia/Riyadh")

        if enabled_providers is not None:
            providers = enabled_providers
        else:
            raw = os.getenv("ENABLED_PROVIDERS", "fmp")
            providers = [p.strip().lower() for p in raw.split(",") if p.strip()]

        # Normalize and de-duplicate providers
        self.enabled_providers: List[str] = []
        for p in providers:
            if p and p not in self.enabled_providers:
                self.enabled_providers.append(p)

        if not self.enabled_providers:
            # Always have at least FMP in the list
            self.enabled_providers = ["fmp"]

        self._cache: Dict[str, _CacheEntry] = {}

        logger.info(
            "DataEngine v2.0 initialized (providers=%s, cache_ttl=%ss, timeout=%ss, v1_delegate=%s)",
            self.enabled_providers,
            self.cache_ttl,
            self.provider_timeout,
            _HAS_V1_ENGINE,
        )

    # ------------------------------------------------------------------ #
    # Public API
    # ------------------------------------------------------------------ #

    async def get_enriched_quote(self, symbol: str) -> UnifiedQuote:
        """
        Main entry point for a single symbol.
        - Uses in-memory cache.
        - Never raises (returns UnifiedQuote with data_quality='MISSING' on errors).
        """
        symbol_norm = self._normalize_symbol(symbol)
        if not symbol_norm:
            return UnifiedQuote(
                symbol="",
                data_quality="MISSING",
                error="Empty or invalid symbol",
            )

        now = time.time()
        cached = self._cache.get(symbol_norm)
        if cached and cached.expires_at > now:
            return cached.quote

        try:
            quote = await self._get_enriched_quote_uncached(symbol_norm)
        except Exception as exc:
            logger.exception("DataEngine.get_enriched_quote exception for %s", symbol_norm)
            quote = UnifiedQuote(
                symbol=symbol_norm,
                data_quality="MISSING",
                error=f"Exception in DataEngine.get_enriched_quote: {exc}",
            )

        # Cache even MISSING responses (short TTL) to avoid hammering providers
        self._cache[symbol_norm] = _CacheEntry(
            expires_at=now + self.cache_ttl,
            quote=quote,
        )
        return quote

    async def get_enriched_quotes(self, symbols: List[str]) -> List[UnifiedQuote]:
        """
        Batch version – concurrently fetches multiple symbols.
        """
        tasks = [self.get_enriched_quote(s) for s in symbols]
        return await asyncio.gather(*tasks)

    # ------------------------------------------------------------------ #
    # Internal helpers
    # ------------------------------------------------------------------ #

    @staticmethod
    def _normalize_symbol(symbol: str) -> str:
        s = (symbol or "").strip().upper()
        if not s:
            return ""

        # Normalize some TADAWUL formats to 1120.SR style
        if s.startswith("TADAWUL:"):
            s = s.split(":", 1)[1].strip()
        if s.endswith(".TADAWUL"):
            s = s.replace(".TADAWUL", ".SR")

        # Ensure .SR suffix for pure numeric KSA tickers
        if s.isdigit():
            s = f"{s}.SR"

        return s

    @staticmethod
    def _is_ksa_symbol(symbol: str) -> bool:
        s = (symbol or "").upper()
        return s.endswith(".SR") or s.endswith(".TADAWUL")

    def _now_dt_pair(self) -> Tuple[datetime, Optional[datetime], Optional[str]]:
        """
        Returns (as_of_utc_dt, as_of_local_dt, timezone_name)
        """
        now_utc = datetime.now(timezone.utc)
        as_of_local: Optional[datetime] = None
        tz_name: Optional[str] = None

        if ZoneInfo is not None:
            try:
                tz = ZoneInfo(self.local_tz_name)
                local_dt = now_utc.astimezone(tz)
                as_of_local = local_dt
                tz_name = self.local_tz_name
            except Exception:
                tz_name = None
                as_of_local = None

        return now_utc, as_of_local, tz_name

    # ------------------------------------------------------------------ #
    # Core fetch + provider orchestration
    # ------------------------------------------------------------------ #

    async def _get_enriched_quote_uncached(self, symbol: str) -> UnifiedQuote:
        is_ksa = self._is_ksa_symbol(symbol)

        # 1) KSA-safe delegate: if legacy core.data_engine is available, use it first
        if is_ksa and _HAS_V1_ENGINE:
            try:
                # v1 engine exposes an async get_enriched_quotes(List[str]) API
                v1_quotes = await _v1_engine.get_enriched_quotes([symbol])  # type: ignore[attr-defined]
                if v1_quotes:
                    logger.debug("Using v1 KSA delegate for %s", symbol)
                    return self._from_v1_quote(v1_quotes[0])
            except Exception as exc:  # pragma: no cover - defensive
                logger.exception("V1 KSA delegate failed for %s: %s", symbol, exc)

        # 2) Multi-provider orchestration (global, and KSA if no v1 delegate)
        providers = list(self.enabled_providers)

        # KSA-safe: never call EODHD for .SR / .TADAWUL symbols
        if is_ksa and "eodhd" in providers:
            providers = [p for p in providers if p != "eodhd"]
            logger.debug(
                "KSA-safe mode: removed EODHD from providers for %s -> %s",
                symbol,
                providers,
            )

        # Map provider name -> coroutine
        tasks: List[asyncio.Task[UnifiedQuote]] = []

        for provider in providers:
            provider = provider.lower()
            if provider == "fmp":
                tasks.append(
                    asyncio.create_task(
                        self._safe_call_provider("fmp", self._fetch_from_fmp, symbol)
                    )
                )
            elif provider == "eodhd":
                tasks.append(
                    asyncio.create_task(
                        self._safe_call_provider("eodhd", self._fetch_from_eodhd, symbol)
                    )
                )
            elif provider == "finnhub":
                tasks.append(
                    asyncio.create_task(
                        self._safe_call_provider("finnhub", self._fetch_from_finnhub, symbol)
                    )
                )
            else:
                logger.warning("Unknown provider '%s' configured; ignoring", provider)

        if not tasks:
            return UnifiedQuote(
                symbol=symbol,
                data_quality="MISSING",
                error="No valid providers configured (ENABLED_PROVIDERS)",
            )

        results = await asyncio.gather(*tasks)

        # Pick the first "OK" result
        for q in results:
            if q.data_quality == "OK":
                return q

        # Otherwise, prefer PARTIAL over MISSING if any
        for q in results:
            if q.data_quality == "PARTIAL":
                return q

        # If all are MISSING, merge error messages
        combined_error = "; ".join(
            [q.error for q in results if q.error]  # type: ignore
        )
        return UnifiedQuote(
            symbol=symbol,
            data_quality="MISSING",
            error=combined_error or "All providers failed or returned no data",
        )

    async def _safe_call_provider(
        self,
        provider_name: str,
        func,
        symbol: str,
    ) -> UnifiedQuote:
        """
        Wrap a provider call so it can never break the engine.
        """
        try:
            q = await func(symbol)
            if q is None:
                return UnifiedQuote(
                    symbol=symbol,
                    data_quality="MISSING",
                    primary_provider=provider_name,
                    provider=provider_name,
                    data_source=provider_name,
                    error=f"{provider_name} returned no data",
                )
            # Ensure provider fields are populated
            q.primary_provider = q.primary_provider or provider_name
            q.provider = q.provider or provider_name
            q.data_source = q.data_source or provider_name
            return q
        except Exception as exc:
            logger.exception(
                "Provider '%s' exception for %s: %s", provider_name, symbol, exc
            )
            return UnifiedQuote(
                symbol=symbol,
                data_quality="MISSING",
                primary_provider=provider_name,
                provider=provider_name,
                data_source=provider_name,
                error=f"Provider {provider_name} exception: {exc}",
            )

    # ------------------------------------------------------------------ #
    # Provider: Financial Modeling Prep (FMP)
    # ------------------------------------------------------------------ #

    async def _fetch_from_fmp(self, symbol: str) -> Optional[UnifiedQuote]:
        api_key = os.getenv("FMP_API_KEY")
        if not api_key:
            logger.warning("FMP_API_KEY not set; skipping FMP for %s", symbol)
            return None

        url = f"https://financialmodelingprep.com/api/v3/quote/{symbol}"

        async with httpx.AsyncClient(timeout=self.provider_timeout) as client:
            resp = await client.get(url, params={"apikey": api_key})
            resp.raise_for_status()
            data = resp.json()

        if not isinstance(data, list) or not data:
            return None

        raw = data[0]
        quote = self._map_fmp_to_unified(symbol, raw)
        quote.primary_provider = "fmp"
        quote.provider = "fmp"
        quote.data_source = "fmp"
        return quote

    def _map_fmp_to_unified(self, symbol: str, d: Dict[str, Any]) -> UnifiedQuote:
        def gv(*keys: str, default=None):
            for k in keys:
                if k in d and d[k] is not None:
                    return d[k]
            return default

        last_price = gv("price")
        previous_close = gv("previousClose")
        change = gv("change")
        change_pct = gv("changesPercentage")

        if change is None and last_price is not None and previous_close:
            try:
                change = float(last_price) - float(previous_close)
            except Exception:
                change = None

        if change_pct is None and change is not None and previous_close:
            try:
                change_pct = (float(change) / float(previous_close)) * 100.0
            except Exception:
                change_pct = None

        high_52w = gv("yearHigh")
        low_52w = gv("yearLow")
        position_52w = None
        if (
            high_52w is not None
            and low_52w is not None
            and last_price is not None
            and high_52w != low_52w
        ):
            try:
                position_52w = (float(last_price) - float(low_52w)) / (
                    float(high_52w) - float(low_52w)
                )
                position_52w *= 100.0
            except Exception:
                position_52w = None

        as_of_utc, as_of_local, tz_name = self._now_dt_pair()

        q = UnifiedQuote(
            symbol=str(gv("symbol", default=symbol)).upper(),
            name=gv("name"),
            company_name=gv("name"),
            market=gv("exchange"),
            market_region=gv("exchange"),
            exchange=gv("exchange"),
            currency=gv("currency"),
            last_price=last_price,
            price=last_price,
            previous_close=previous_close,
            prev_close=previous_close,
            open=gv("open"),
            high=gv("dayHigh"),
            low=gv("dayLow"),
            change=change,
            change_percent=change_pct,
            change_pct=change_pct,
            high_52w=high_52w,
            low_52w=low_52w,
            fifty_two_week_high=high_52w,
            fifty_two_week_low=low_52w,
            position_52w_percent=position_52w,
            fifty_two_week_position=position_52w,
            volume=gv("volume"),
            avg_volume_30d=gv("avgVolume"),
            average_volume_30d=gv("avgVolume"),
            avg_volume=gv("avgVolume"),
            market_cap=gv("marketCap"),
            eps_ttm=gv("eps"),
            eps=gv("eps"),
            pe_ratio=gv("pe"),
            pe=gv("pe"),
            pe_ttm=gv("pe"),
            beta=gv("beta"),
            ma_50d=gv("priceAvg50"),
            data_quality="OK" if last_price is not None else "PARTIAL",
            last_updated_utc=as_of_utc,
            last_updated_riyadh=as_of_local,
            as_of_utc=as_of_utc,
            as_of_local=as_of_local,
            timezone=tz_name,
            raw=d,
        )

        if self.enable_advanced_analysis:
            self._apply_basic_scoring(q, source="fmp")

        return q

    # ------------------------------------------------------------------ #
    # Provider: EODHD (optional – mainly for global, not KSA .SR)
    # ------------------------------------------------------------------ #

    async def _fetch_from_eodhd(self, symbol: str) -> Optional[UnifiedQuote]:
        api_key = os.getenv("EODHD_API_KEY")
        base_url = os.getenv("EODHD_BASE_URL", "https://eodhd.com/api")

        if not api_key:
            logger.warning("EODHD_API_KEY not set; skipping EODHD for %s", symbol)
            return None

        url = f"{base_url.rstrip('/')}/real-time/{symbol}"
        params = {"api_token": api_key, "fmt": "json"}

        async with httpx.AsyncClient(timeout=self.provider_timeout) as client:
            resp = await client.get(url, params=params)
            resp.raise_for_status()
            d = resp.json()

        if not isinstance(d, dict) or not d:
            return None

        q = self._map_eodhd_to_unified(symbol, d)
        q.primary_provider = "eodhd"
        q.provider = "eodhd"
        q.data_source = "eodhd"
        return q

    def _map_eodhd_to_unified(self, symbol: str, d: Dict[str, Any]) -> UnifiedQuote:
        def gv(*keys: str, default=None):
            for k in keys:
                if k in d and d[k] is not None:
                    return d[k]
            return default

        last_price = gv("close", "price", "last")
        previous_close = gv("previousClose", "previous_close")
        change = gv("change")
        change_pct = gv("change_p", "change_percent")

        if change is None and last_price is not None and previous_close:
            try:
                change = float(last_price) - float(previous_close)
            except Exception:
                change = None

        if change_pct is None and change is not None and previous_close:
            try:
                change_pct = (float(change) / float(previous_close)) * 100.0
            except Exception:
                change_pct = None

        high_52w = gv("fifty_two_week_high", "high_52w")
        low_52w = gv("fifty_two_week_low", "low_52w")
        position_52w = gv("fifty_two_week_position", "position_52w_percent")

        if (
            position_52w is None
            and high_52w is not None
            and low_52w is not None
            and last_price is not None
            and high_52w != low_52w
        ):
            try:
                position_52w = (float(last_price) - float(low_52w)) / (
                    float(high_52w) - float(low_52w)
                )
                position_52w *= 100.0
            except Exception:
                position_52w = None

        as_of_utc, as_of_local, tz_name = self._now_dt_pair()

        q = UnifiedQuote(
            symbol=str(gv("code", "symbol", default=symbol)).upper(),
            name=gv("name"),
            company_name=gv("name"),
            market=gv("exchange_short_name", "exchange"),
            market_region=gv("exchange_short_name", "exchange"),
            exchange=gv("exchange_short_name", "exchange"),
            currency=gv("currency", "currency_code"),
            last_price=last_price,
            price=last_price,
            previous_close=previous_close,
            prev_close=previous_close,
            open=gv("open"),
            high=gv("high"),
            low=gv("low"),
            change=change,
            change_percent=change_pct,
            change_pct=change_pct,
            high_52w=high_52w,
            low_52w=low_52w,
            fifty_two_week_high=high_52w,
            fifty_two_week_low=low_52w,
            position_52w_percent=position_52w,
            fifty_two_week_position=position_52w,
            volume=gv("volume"),
            data_quality="OK" if last_price is not None else "PARTIAL",
            last_updated_utc=as_of_utc,
            last_updated_riyadh=as_of_local,
            as_of_utc=as_of_utc,
            as_of_local=as_of_local,
            timezone=tz_name,
            raw=d,
        )

        if self.enable_advanced_analysis:
            self._apply_basic_scoring(q, source="eodhd")

        return q

    # ------------------------------------------------------------------ #
    # Provider: Finnhub (optional – real-time price only)
    # ------------------------------------------------------------------ #

    async def _fetch_from_finnhub(self, symbol: str) -> Optional[UnifiedQuote]:
        api_key = os.getenv("FINNHUB_API_KEY")
        if not api_key:
            logger.warning("FINNHUB_API_KEY not set; skipping Finnhub for %s", symbol)
            return None

        url = "https://finnhub.io/api/v1/quote"
        params = {"symbol": symbol, "token": api_key}

        async with httpx.AsyncClient(timeout=self.provider_timeout) as client:
            resp = await client.get(url, params=params)
            resp.raise_for_status()
            d = resp.json()

        if not isinstance(d, dict) or not d:
            return None

        # Finnhub uses c/h/l/o/pc/t format
        last_price = d.get("c")
        previous_close = d.get("pc")
        open_price = d.get("o")
        high = d.get("h")
        low = d.get("l")

        change = None
        change_pct = None
        if last_price is not None and previous_close:
            try:
                change = float(last_price) - float(previous_close)
                change_pct = (float(change) / float(previous_close)) * 100.0
            except Exception:
                change = None
                change_pct = None

        as_of_utc, as_of_local, tz_name = self._now_dt_pair()

        q = UnifiedQuote(
            symbol=symbol.upper(),
            last_price=last_price,
            price=last_price,
            previous_close=previous_close,
            prev_close=previous_close,
            open=open_price,
            high=high,
            low=low,
            change=change,
            change_percent=change_pct,
            change_pct=change_pct,
            volume=None,  # Finnhub quote doesn't always include volume here
            data_quality="PARTIAL" if last_price is not None else "MISSING",
            last_updated_utc=as_of_utc,
            last_updated_riyadh=as_of_local,
            as_of_utc=as_of_utc,
            as_of_local=as_of_local,
            timezone=tz_name,
            raw=d,
        )

        if self.enable_advanced_analysis:
            self._apply_basic_scoring(q, source="finnhub")

        return q

    # ------------------------------------------------------------------ #
    # KSA delegate mapping (from v1 UnifiedQuote to v2 UnifiedQuote)
    # ------------------------------------------------------------------ #

    def _from_v1_quote(self, v1_q: Any) -> UnifiedQuote:
        """
        Map a core.data_engine.UnifiedQuote (v1) instance to this v2 UnifiedQuote.
        This keeps all legacy fields while aligning with the 9-page template.
        """

        def gv(*names: str, default=None):
            for n in names:
                if hasattr(v1_q, n):
                    val = getattr(v1_q, n)
                    if val is not None:
                        return val
            return default

        symbol = (gv("symbol", "ticker", default="") or "").upper()
        name = gv("company_name", "name")
        sector = gv("sector")
        sub_sector = gv("sub_sector", "industry_group")
        industry = gv("industry")
        market = gv("market", "market_region", "exchange")
        market_region = gv("market_region", "market")
        exchange = gv("exchange")
        currency = gv("currency")

        last_price = gv("price", "last_price")
        previous_close = gv("prev_close", "previous_close")
        open_price = gv("open")
        high = gv("high")
        low = gv("low")
        change = gv("change")
        change_pct = gv("change_pct", "change_percent")

        high_52w = gv("fifty_two_week_high", "high_52w")
        low_52w = gv("fifty_two_week_low", "low_52w")
        pos_52w = gv("fifty_two_week_position", "position_52w_percent")

        volume = gv("volume")
        avg_volume = gv("avg_volume", "avg_volume_30d")
        market_cap = gv("market_cap")
        shares_outstanding = gv("shares_outstanding")
        free_float = gv("free_float")

        eps_ttm = gv("eps_ttm", "eps")
        pe_ttm = gv("pe_ttm", "pe", "pe_ratio")
        pb = gv("pb", "pb_ratio")
        dividend_yield = gv("dividend_yield", "dividend_yield_percent")
        roe = gv("roe")
        roa = gv("roa")
        profit_margin = gv("profit_margin", "net_margin_percent")
        debt_to_equity = gv("debt_to_equity")

        data_quality = gv("data_quality", default="UNKNOWN")
        sources = gv("sources")
        last_updated_utc = gv("last_updated_utc")
        last_updated_riyadh = gv("last_updated_riyadh", "last_updated_local")

        as_of_utc = last_updated_utc
        as_of_local = last_updated_riyadh
        tz_name = gv("timezone")

        if last_updated_utc is None:
            # Fall back to "now" if v1 doesn't provide timestamps
            as_of_utc, as_of_local, tz_name = self._now_dt_pair()
            last_updated_utc = as_of_utc
            last_updated_riyadh = as_of_local

        provider = None
        primary_provider = None
        provider_sources: Optional[List[ProviderSource]] = None

        if sources:
            try:
                if isinstance(sources, list) and sources:
                    tmp_sources: List[ProviderSource] = []
                    for s in sources:
                        if isinstance(s, dict):
                            prov = str(
                                s.get("provider")
                                or s.get("name")
                                or s.get("source")
                                or ""
                            )
                            tmp_sources.append(
                                ProviderSource(
                                    provider=prov,
                                    weight=s.get("weight"),
                                    quality=s.get("quality"),
                                )
                            )
                        else:
                            prov = str(
                                getattr(s, "provider", None)
                                or getattr(s, "name", None)
                                or getattr(s, "source", None)
                                or ""
                            )
                            tmp_sources.append(
                                ProviderSource(
                                    provider=prov,
                                    weight=getattr(s, "weight", None),
                                    quality=getattr(s, "quality", None),
                                )
                            )
                    provider_sources = tmp_sources
                    if tmp_sources:
                        primary_provider = tmp_sources[0].provider
                        provider = primary_provider
            except Exception:  # pragma: no cover - extremely defensive
                provider_sources = None
                provider = None
                primary_provider = None

        q = UnifiedQuote(
            symbol=symbol,
            name=name,
            company_name=name,
            sector=sector,
            sub_sector=sub_sector,
            industry=industry,
            market=market,
            market_region=market_region,
            exchange=exchange,
            currency=currency,
            shares_outstanding=shares_outstanding,
            free_float=free_float,
            last_price=last_price,
            price=last_price,
            previous_close=previous_close,
            prev_close=previous_close,
            open=open_price,
            high=high,
            low=low,
            change=change,
            change_percent=change_pct,
            change_pct=change_pct,
            high_52w=high_52w,
            low_52w=low_52w,
            fifty_two_week_high=high_52w,
            fifty_two_week_low=low_52w,
            position_52w_percent=pos_52w,
            fifty_two_week_position=pos_52w,
            volume=volume,
            avg_volume_30d=avg_volume,
            average_volume_30d=avg_volume,
            avg_volume=avg_volume,
            market_cap=market_cap,
            eps_ttm=eps_ttm,
            eps=eps_ttm,
            pe_ratio=pe_ttm,
            pe=pe_ttm,
            pe_ttm=pe_ttm,
            pb_ratio=pb,
            pb=pb,
            dividend_yield=dividend_yield,
            dividend_yield_percent=dividend_yield,
            roe=roe,
            roe_percent=roe,
            roa=roa,
            roa_percent=roa,
            profit_margin=profit_margin,
            net_margin_percent=profit_margin,
            debt_to_equity=debt_to_equity,
            data_quality=data_quality,
            primary_provider=primary_provider,
            provider=provider,
            data_source=provider,
            sources=provider_sources,
            last_updated_utc=last_updated_utc,
            last_updated_riyadh=last_updated_riyadh,
            as_of_utc=as_of_utc,
            as_of_local=as_of_local,
            timezone=tz_name,
            raw=None,
        )

        if self.enable_advanced_analysis:
            self._apply_basic_scoring(q, source="v1_delegate")

        return q

    # ------------------------------------------------------------------ #
    # Basic AI-style scoring (Value / Quality / Momentum / Opportunity)
    # ------------------------------------------------------------------ #

    def _apply_basic_scoring(self, q: UnifiedQuote, source: str) -> None:
        """
        Lightweight scoring engine:
        - Value score: based mainly on PE and dividend yield
        - Quality score: EPS sign + PE range
        - Momentum score: % change + 52W position
        - Opportunity score: weighted combination
        """
        # Quality score
        quality = 50.0
        pe = q.pe_ratio or q.pe or q.pe_ttm
        eps = q.eps_ttm or q.eps

        if eps is not None and eps > 0 and pe is not None and pe > 0:
            if pe < 10:
                quality = 80.0
            elif pe < 20:
                quality = 70.0
            elif pe < 30:
                quality = 60.0
            else:
                quality = 50.0
        elif eps is not None and eps <= 0:
            quality = 30.0

        # Value score
        value = 50.0
        if pe is not None and pe > 0:
            try:
                # 10 PE -> ~67, 20 PE -> ~50, 5 PE -> ~80, very rough
                value = max(10.0, min(90.0, 100.0 / (1.0 + pe / 10.0)))
            except Exception:
                value = 50.0

        dy = q.dividend_yield_percent or q.dividend_yield
        if dy is not None and dy > 0:
            try:
                value = min(90.0, value + min(20.0, float(dy)))
            except Exception:
                pass

        # Momentum score
        momentum = 50.0
        if q.change_percent is not None or q.change_pct is not None:
            try:
                cp = float(
                    q.change_percent if q.change_percent is not None else q.change_pct  # type: ignore[arg-type]
                )
                momentum += max(-20.0, min(20.0, cp))
            except Exception:
                pass

        if q.position_52w_percent is not None:
            try:
                p = float(q.position_52w_percent)
                if p > 80:
                    momentum += 5.0
                elif p < 20:
                    momentum -= 5.0
            except Exception:
                pass

        # Clamp scores
        value = max(0.0, min(100.0, value))
        quality = max(0.0, min(100.0, quality))
        momentum = max(0.0, min(100.0, momentum))

        # Opportunity score (weighted)
        opportunity = value * 0.4 + quality * 0.3 + momentum * 0.3

        q.value_score = round(value, 2)
        q.quality_score = round(quality, 2)
        q.momentum_score = round(momentum, 2)
        q.opportunity_score = round(opportunity, 2)

        # Rough recommendation buckets
        if opportunity >= 80:
            q.recommendation = "STRONG_BUY"
        elif opportunity >= 65:
            q.recommendation = "BUY"
        elif opportunity >= 50:
            q.recommendation = "HOLD"
        elif opportunity >= 35:
            q.recommendation = "REDUCE"
        else:
            q.recommendation = "SELL"

        # Valuation label based on value score
        if q.value_score is not None:
            if q.value_score >= 80:
                q.valuation_label = "DEEP_VALUE"
            elif q.value_score >= 65:
                q.valuation_label = "UNDERVALUED"
            elif q.value_score >= 45:
                q.valuation_label = "FAIR_VALUE"
            else:
                q.valuation_label = "EXPENSIVE"


__all__ = ["UnifiedQuote", "ProviderSource", "DataEngine"]
